{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ● Python of GIS  MingHsun 2016/03/05\n",
    "* GIS在Python! GIS的使用者，一般而言都會使用GIS軟體進行操作，但是現在地理資料越來越發多，而資料分析的流程當中，data cleaning是非常重要的一個環節，尤其是地理資料，並不是所有的資料都已經處理成GIS軟體可以讀取格式，尤其是在大量資料需要進行轉換與處理的時候，使用GIS軟體進行操作就會有困難，雖然在ArcGIS之有Model Builder可以使用，但如果可以在程式語言之中使用GIS的操作分析功能+其他的程式語言功能將會非常的方便，而尤其在Python之中不管是資料擷取、分析、探勘、視覺化的模組相當多元，在配合上GIS的功能，可以使用Pytho做出非常多都的目標，以下為Python一些GIS相關的模組。\n",
    "\n",
    "\n",
    "\n",
    "## Python主要模組操作與介紹:<br>\n",
    "\n",
    "## pyproj\n",
    "* 座標投影轉換模組，在地理資料當中空間座標投影是相當重要的一個問題，例如\n",
    ">1.經緯度座標系統或是投影座標系統的轉換\n",
    " 2.投影座標系統之間的轉換\n",
    "* pyproj就是主要解決這些座標系統轉換的問題，也同是可以做些大地測量的計算\n",
    "\n",
    "\n",
    "## GDAL (Geospatial Data Abstraction Library)\n",
    "* 事實上在GDAL之中包含了兩個libraries\n",
    "> 1.GDAL對 Raster Data 進行操作<br>\n",
    "  2.OGR 對 Vector Data 進行操作\n",
    "\n",
    "\n",
    "## arcpy\n",
    "* 可以對於地理資料\n",
    ">data analysis<br>\n",
    "data conversion<br>\n",
    "data management<br>\n",
    "map automation<br>\n",
    "\n",
    "* 就是Pyhton化的ArcGIS，透過Pyhton程式語言來使用ArcGIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例1.Creat Shapefile\n",
    "### 將大量具有座標的Point資料的csv檔案，使用Python轉換成Shapefile檔案。\n",
    "> 1.讀取csv資料<br>\n",
    "  2.進行資料處理<br>\n",
    "  3.設定所需要之參數<br>\n",
    "  4.轉換成Shapefile檔案<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 原始抓取在csv之中的Point點資料，並同時做資料的數量確認(在taipeibox資料夾中)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001 10 points 97\n",
      "2002 46 points 741\n",
      "2003 57 points 1127\n",
      "2004 89 points 1693\n",
      "2005 190 points 13286\n",
      "2006 349 points 19182\n",
      "2007 611 points 50219\n",
      "2008 1095 points 90422\n",
      "2009 2103 points 132092\n",
      "2010 3108 points 162428\n",
      "2011 3843 points 201035\n",
      "2012 3989 points 201645\n",
      "2013 6004 points 299742\n",
      "2014 5091 points 257018\n",
      "2015 3635 points 164934\n",
      "UNIQUE all userID: 17181\n",
      "SUM of points 1595661\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "total=0\n",
    "all_uid=[]\n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "for yy in y_list:\n",
    "    d=0\n",
    "    y=str(yy)\n",
    "    uid_check=[]\n",
    "    f = open('taipeibox/'+y+'.csv', 'r')  \n",
    "    for row in csv.reader(f):  \n",
    "        d=d+1\n",
    "        total=total+1\n",
    "        uid_check.append(row[1])\n",
    "        all_uid.append(row[1])\n",
    "    f.close()\n",
    "    print y,len(set(uid_check)),\"points\",d\n",
    "print \"UNIQUE all userID:\",len(set(all_uid)) \n",
    "print \"SUM of points\",total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 資料格式處理 (座標投影轉換/屬性欄位格式轉換)&輸出.csv(自:taipeibox資料夾 存:taipeibox_process資料夾)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001 year before 96 after 96\n",
      "2002 year before 740 after 740\n",
      "2003 year before 1126 after 1126\n",
      "2004 year before 1692 after 1692\n",
      "2005 year before 13248 after 13248\n",
      "2006 year before 19156 after 19156\n",
      "2007 year before 50168 after 50168\n",
      "2008 year before 90352 after 90347\n",
      "2009 year before 131990 after 131986\n",
      "2010 year before 162296 after 162263\n",
      "2011 year before 200881 after 200623\n",
      "2012 year before 201500 after 201470\n",
      "2013 year before 299529 after 299244\n",
      "2014 year before 256825 after 256629\n",
      "2015 year before 164819 after 164670\n"
     ]
    }
   ],
   "source": [
    "import pyproj\n",
    "import time\n",
    "import csv \n",
    "# 選擇要抓取的年份\n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "prj = pyproj.Proj(init=\"epsg:3828\")\n",
    "point_dict={}#checkdict\n",
    "point_list=[]#userID_list\n",
    "for yy in y_list:\n",
    "    b=0\n",
    "    a=0\n",
    "    year=str(yy)\n",
    "    uid_check=[]\n",
    "    f = open('taipeibox/'+year+'.csv', 'r')  \n",
    "    nf = open(\"taipeibox_process/\"+str(year)+\".csv\",\"w\") \n",
    "    rewrite_list=[[\"timestamp\",\"time_D\",\"time_T\",\"logitude\",\"latitude\",\"X\",\"Y\",\"photo_ID\",\"user_ID\"]]\n",
    "    for point in csv.reader(f):  \n",
    "        if point[0]!=\"photoID\":\n",
    "            ph_ID=point[0]\n",
    "            u_ID=point[1]\n",
    "            ph_time=point[3]\n",
    "            x=point[5]\n",
    "            y=point[4]\n",
    "            b=b+1\n",
    "            if x==\"0\" and y==\"0\":\n",
    "                continue\n",
    "            a=a+1\n",
    "            split_=ph_time.split()#'2001-10-06 14:58:45'將日期,時間切開\n",
    "            split_D=split_[0].split('-') #將2014/-2-19 依據'-'切割\n",
    "            split_T=split_[1].split(':') #將03:00:49 依據':'切割\n",
    "            split_D[1]=split_D[1].zfill(2)\n",
    "            split_D[2]=split_D[2].zfill(2)\n",
    "            D_s=split_D[0]+split_D[1]+split_D[2]\n",
    "            T_s=split_T[0]+split_T[1]+split_T[2]\n",
    "            #投影轉換\n",
    "            photoPx, photoPy = prj(x,y, inverse=False)\n",
    "            ph_x=\"{:.7f}\".format(photoPx)\n",
    "            ph_y=\"{:.7f}\".format(photoPy)\n",
    "            time_tuple=(int(split_D[0]), int(split_D[1]), int(split_D[2]), int(split_T[0]), int(split_T[1]),int(split_T[2]), 0, 0, 0)\n",
    "            timestamp=time.mktime(time_tuple) \n",
    "            temp_list=[timestamp,D_s,T_s,x,y,ph_x,ph_y,ph_ID,u_ID]\n",
    "            point_list.append(temp_list)\n",
    "            rewrite_list.append(temp_list)\n",
    "            if u_ID not in point_dict:\n",
    "                point_dict.setdefault(u_ID,[temp_list])\n",
    "            else:\n",
    "                point_dict[u_ID].append(temp_list)\n",
    "    w = csv.writer(nf)  \n",
    "    w.writerows(rewrite_list)\n",
    "    f.close()\n",
    "    nf.close()\n",
    "    print year,\"year\",\"before\",b,\"after\",a\n",
    "#資料缺少 因為當中有x=0 y=0的資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 本次使對於向量資料進行操綽，使用ogr來將上述的csv資料輸出成Shapefile(自:taipeibox_process 存入:process_shp資料夾)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import osgeo.ogr as ogr\n",
    "import osgeo.osr as osr\n",
    "import csv \n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "# y_list=[2005]\n",
    "# Attribute欄位建立與欄位type定義\n",
    "    layer.CreateField(ogr.FieldDefn(\"time_D\", ogr.OFTInteger))\n",
    "    layer.CreateField(ogr.FieldDefn(\"time_T\", ogr.OFTInteger))\n",
    "    layer.CreateField(ogr.FieldDefn(\"Latitude\", ogr.OFTReal))\n",
    "    layer.CreateField(ogr.FieldDefn(\"Longitude\", ogr.OFTReal))\n",
    "    layer.CreateField(ogr.FieldDefn(\"Timestamp\", ogr.OFTInteger))\n",
    "    layer.CreateField(ogr.FieldDefn(\"X\", ogr.OFTReal))\n",
    "    layer.CreateField(ogr.FieldDefn(\"Y\", ogr.OFTReal))\n",
    "    # Process the text file and add the attributes and features to the shapefile\n",
    "    f = open('taipeibox_process/'+y+'.csv', 'r')  \n",
    "    for point in csv.reader(f):\n",
    "        if point[0]!=\"timestamp\":\n",
    "            # create the feature\n",
    "            feature = ogr.Feature(layer.GetLayerDefn())\n",
    "            # Set the attributes\n",
    "            feature.SetField(\"photoID\",point[7])\n",
    "            feature.SetField(\"userID\", point[8])\n",
    "            feature.SetField(\"time_D\", point[1])\n",
    "            feature.SetField(\"time_T\", point[2])\n",
    "            feature.SetField(\"Longitude\",point[3])\n",
    "            feature.SetField(\"Latitude\", point[4])\n",
    "            feature.SetField(\"Timestamp\",point[0])\n",
    "            feature.SetField(\"X\", point[5])\n",
    "            feature.SetField(\"Y\", point[6])\n",
    "\n",
    "            c_logitude=float(point[3])\n",
    "            c_latitude=float(point[4])\n",
    "            # create the WKT for the feature using Python string formatting\n",
    "            wkt = \"POINT(%f %f)\" %  (float(c_logitude) , float(c_latitude))\n",
    "\n",
    "            # Create the point from the Well Known Txt\n",
    "            point = ogr.CreateGeometryFromWkt(wkt)\n",
    "\n",
    "            # Set the feature geometry using the point\n",
    "            feature.SetGeometry(point)\n",
    "            # Create the feature in the layer (shapefile)\n",
    "            layer.CreateFeature(feature)\n",
    "            # Destroy the feature to free resources\n",
    "            feature.Destroy()\n",
    "    # Destroy the data source to free resources\n",
    "    data_source.Destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例2. 基礎的GIS操作。\n",
    "* 將以上步驟，自csv轉換出來的Shapefile資料進行GIS操作\n",
    "* Clip\n",
    "* Feature count\n",
    "* Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip  (arcpy)\n",
    "Syntax\n",
    ">Clip_analysis (in_features, clip_features, out_feature_class, {cluster_tolerance})\n",
    "\n",
    "* 讀取taipei shp將資料clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "for yy in y_list:\n",
    "    y=str(yy)\n",
    "    c_shp= \"process_shp/\"+y+\".shp\"\n",
    "    arcpy.Clip_analysis(c_shp, \"tpe_shp/taipei_city.shp\", \"C:/thesis_flickr/clip/\"+y+\"clip.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Count \n",
    "Syntax\n",
    ">layer.GetFeatureCount()\n",
    "\n",
    "* 讀取clip後的資料\n",
    "* 並對資料進行確認與分析(這些資料是Flickr平台擷取下來，據有Geotag的相片資料，在對於資料進行確認的部分，重點在於照片的位置、拍照時間是否有重疊，對於此類社群媒體平台所截取的資料，資料的清理與確認是非常重要且繁複的步驟，以便後續的資料使用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001 points 94 unique uid 8\n",
      "unique time_location 92\n",
      "unique_location 19\n",
      "2002 points 699 unique uid 40\n",
      "unique time_location 673\n",
      "unique_location 113\n",
      "2003 points 1051 unique uid 51\n",
      "unique time_location 1018\n",
      "unique_location 88\n",
      "2004 points 1547 unique uid 78\n",
      "unique time_location 1510\n",
      "unique_location 149\n",
      "2005 points 12866 unique uid 172\n",
      "unique time_location 12775\n",
      "unique_location 875\n",
      "2006 points 16777 unique uid 317\n",
      "unique time_location 16508\n",
      "unique_location 2295\n",
      "2007 points 44124 unique uid 563\n",
      "unique time_location 43448\n",
      "unique_location 7438\n",
      "2008 points 83471 unique uid 986\n",
      "unique time_location 80738\n",
      "unique_location 15322\n",
      "2009 points 116059 unique uid 1886\n",
      "unique time_location 114014\n",
      "unique_location 23326\n",
      "2010 points 144293 unique uid 2770\n",
      "unique time_location 141822\n",
      "unique_location 32205\n",
      "2011 points 176325 unique uid 3487\n",
      "unique time_location 172328\n",
      "unique_location 47292\n",
      "2012 points 169001 unique uid 3635\n",
      "unique time_location 160694\n",
      "unique_location 54001\n",
      "2013 points 239293 unique uid 5343\n",
      "unique time_location 229915\n",
      "unique_location 94633\n",
      "2014 points 209702 unique uid 4650\n",
      "unique time_location 202421\n",
      "unique_location 101319\n",
      "2015 points 137198 unique uid 3332\n",
      "unique time_location 130696\n",
      "unique_location 65808\n",
      "SUM of points 2705000\n",
      "UNIQUE all userID: 15735\n",
      "UNIQUE all time_location: 1310128\n",
      "UNIQUE all location: 425254\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from osgeo import ogr\n",
    "total=0\n",
    "all_uid=[]\n",
    "all_t_l=[]\n",
    "all_l=[]\n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "for yy in y_list:\n",
    "    year=str(yy)\n",
    "    uid_check=[]\n",
    "    t_l_check=[]\n",
    "    l_check=[]\n",
    "    SHP= \"clip/\"+year+\"clip.shp\"\n",
    "    daShapefile = SHP\n",
    "    driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "    dataSource = driver.Open(daShapefile, 0) # 0 means read-only. 1 means writeable. \n",
    "    layer = dataSource.GetLayer(0)\n",
    "    featureCount = layer.GetFeatureCount()\n",
    "    total=total+featureCount\n",
    "    for feature in layer:\n",
    "        userID = feature.GetField('userID')\n",
    "        timestamp = feature.GetField('timestamp')\n",
    "        x= feature.GetField('x')\n",
    "        y= feature.GetField('y')\n",
    "        total=total+1\n",
    "        uid_check.append(userID)\n",
    "        t_l_check.append(str(timestamp)+str(x)+str(y))\n",
    "        all_uid.append(userID)\n",
    "        all_t_l.append(userID+str(timestamp)+str(x)+str(y))\n",
    "        l_check.append(str(x)+str(y))\n",
    "        all_l.append(str(x)+str(y))\n",
    "    # Destroy the data source to free resources\n",
    "    dataSource.Destroy()\n",
    "    print year,\"points\",featureCount,\"unique uid\",len(set(uid_check))\n",
    "    print \"unique time_location\",len(set(t_l_check))\n",
    "    print \"unique_location\",len(set(l_check))\n",
    "print \"SUM of points\",total\n",
    "print \"UNIQUE all userID:\",len(set(all_uid))\n",
    "print \"UNIQUE all time_location:\",len(set(all_t_l))\n",
    "print \"UNIQUE all location:\",len(set(all_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge  (arcpy)\n",
    "Syntax\n",
    ">Merge_management (inputs, output, {field_mappings})<br>\n",
    "\n",
    "* 將多張Shapefile資料進行Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "arcpy.env.workspace = \"C:/thesis_flickr/clip\"\n",
    "merge_list=[]\n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "for yy in y_list:\n",
    "    year=str(yy)\n",
    "    shp= year+\"clip.shp\"\n",
    "    merge_list.append(shp)\n",
    "print merge_list\n",
    "# #delete shp\n",
    "if os.path.exists(\"merge.shp\"):\n",
    "    driver.DeleteDataSource(\"merge.shp\")\n",
    "arcpy.Merge_management(merge_list, \"C:/thesis_flickr/merge.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get merged feature count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1352500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from osgeo import ogr\n",
    "SHP= \"merge.shp\"\n",
    "daShapefile = SHP\n",
    "driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "dataSource = driver.Open(daShapefile, 0) # 0 means read-only. 1 means writeable. \n",
    "layer = dataSource.GetLayer(0)\n",
    "featureCount = layer.GetFeatureCount()\n",
    "print featureCount\n",
    "# Destroy the data source to free resources\n",
    "dataSource.Destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
