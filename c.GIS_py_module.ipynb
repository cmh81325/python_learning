{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ● python GIS 常用模組 MingHsun 2016/03/05\n",
    "### module pyproj, gdal,arcpy\n",
    "## 功能:\n",
    "#### 1.create shpfile\n",
    "#### 2.clip\n",
    "#### 3.merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#原始抓取資料的數量確認(在taipeibox資料夾中)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001 10 points 97\n",
      "2002 46 points 741\n",
      "2003 57 points 1127\n",
      "2004 89 points 1693\n",
      "2005 190 points 13286\n",
      "2006 349 points 19182\n",
      "2007 611 points 50219\n",
      "2008 1095 points 90422\n",
      "2009 2103 points 132092\n",
      "2010 3108 points 162428\n",
      "2011 3843 points 201035\n",
      "2012 3989 points 201645\n",
      "2013 6004 points 299742\n",
      "2014 5091 points 257018\n",
      "2015 3635 points 164934\n",
      "UNIQUE all userID: 17181\n",
      "SUM of points 1595661\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "total=0\n",
    "all_uid=[]\n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "for yy in y_list:\n",
    "    d=0\n",
    "    y=str(yy)\n",
    "    uid_check=[]\n",
    "    f = open('taipeibox/'+y+'.csv', 'r')  \n",
    "    for row in csv.reader(f):  \n",
    "        d=d+1\n",
    "        total=total+1\n",
    "        uid_check.append(row[1])\n",
    "        all_uid.append(row[1])\n",
    "    f.close()\n",
    "    print y,len(set(uid_check)),\"points\",d\n",
    "print \"UNIQUE all userID:\",len(set(all_uid)) \n",
    "print \"SUM of points\",total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#資料格式處理&輸出.csv(自:taipeibox資料夾 存:taipeibox_process資料夾)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001 year before 96 after 96\n",
      "2002 year before 740 after 740\n",
      "2003 year before 1126 after 1126\n",
      "2004 year before 1692 after 1692\n",
      "2005 year before 13248 after 13248\n",
      "2006 year before 19156 after 19156\n",
      "2007 year before 50168 after 50168\n",
      "2008 year before 90352 after 90347\n",
      "2009 year before 131990 after 131986\n",
      "2010 year before 162296 after 162263\n",
      "2011 year before 200881 after 200623\n",
      "2012 year before 201500 after 201470\n",
      "2013 year before 299529 after 299244\n",
      "2014 year before 256825 after 256629\n",
      "2015 year before 164819 after 164670\n"
     ]
    }
   ],
   "source": [
    "import pyproj\n",
    "import time\n",
    "import csv \n",
    "# 選擇要抓取的年份\n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "prj = pyproj.Proj(init=\"epsg:3828\")\n",
    "point_dict={}#checkdict\n",
    "point_list=[]#userID_list\n",
    "for yy in y_list:\n",
    "    b=0\n",
    "    a=0\n",
    "    year=str(yy)\n",
    "    uid_check=[]\n",
    "    f = open('taipeibox/'+year+'.csv', 'r')  \n",
    "    nf = open(\"taipeibox_process/\"+str(year)+\".csv\",\"w\") \n",
    "    rewrite_list=[[\"timestamp\",\"time_D\",\"time_T\",\"logitude\",\"latitude\",\"X\",\"Y\",\"photo_ID\",\"user_ID\"]]\n",
    "    for point in csv.reader(f):  \n",
    "        if point[0]!=\"photoID\":\n",
    "            ph_ID=point[0]\n",
    "            u_ID=point[1]\n",
    "            ph_time=point[3]\n",
    "            x=point[5]\n",
    "            y=point[4]\n",
    "            b=b+1\n",
    "            if x==\"0\" and y==\"0\":\n",
    "                continue\n",
    "            a=a+1\n",
    "            split_=ph_time.split()#'2001-10-06 14:58:45'將日期,時間切開\n",
    "            split_D=split_[0].split('-') #將2014/-2-19 依據'-'切割\n",
    "            split_T=split_[1].split(':') #將03:00:49 依據':'切割\n",
    "            split_D[1]=split_D[1].zfill(2)\n",
    "            split_D[2]=split_D[2].zfill(2)\n",
    "            D_s=split_D[0]+split_D[1]+split_D[2]\n",
    "            T_s=split_T[0]+split_T[1]+split_T[2]\n",
    "            #投影轉換\n",
    "            photoPx, photoPy = prj(x,y, inverse=False)\n",
    "            ph_x=\"{:.7f}\".format(photoPx)\n",
    "            ph_y=\"{:.7f}\".format(photoPy)\n",
    "            time_tuple=(int(split_D[0]), int(split_D[1]), int(split_D[2]), int(split_T[0]), int(split_T[1]),int(split_T[2]), 0, 0, 0)\n",
    "            timestamp=time.mktime(time_tuple) \n",
    "            temp_list=[timestamp,D_s,T_s,x,y,ph_x,ph_y,ph_ID,u_ID]\n",
    "            point_list.append(temp_list)\n",
    "            rewrite_list.append(temp_list)\n",
    "            if u_ID not in point_dict:\n",
    "                point_dict.setdefault(u_ID,[temp_list])\n",
    "            else:\n",
    "                point_dict[u_ID].append(temp_list)\n",
    "    w = csv.writer(nf)  \n",
    "    w.writerows(rewrite_list)\n",
    "    f.close()\n",
    "    nf.close()\n",
    "    print year,\"year\",\"before\",b,\"after\",a\n",
    "#資料缺少 因為當中有x=0 y=0的資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#輸出成shp(自:taipeibox_process 存入:process_shp資料夾)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import osgeo.ogr as ogr\n",
    "import osgeo.osr as osr\n",
    "import csv \n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "# y_list=[2005]\n",
    "-\n",
    "    layer.CreateField(ogr.FieldDefn(\"time_D\", ogr.OFTInteger))\n",
    "    layer.CreateField(ogr.FieldDefn(\"time_T\", ogr.OFTInteger))\n",
    "    layer.CreateField(ogr.FieldDefn(\"Latitude\", ogr.OFTReal))\n",
    "    layer.CreateField(ogr.FieldDefn(\"Longitude\", ogr.OFTReal))\n",
    "    layer.CreateField(ogr.FieldDefn(\"Timestamp\", ogr.OFTInteger))\n",
    "    layer.CreateField(ogr.FieldDefn(\"X\", ogr.OFTReal))\n",
    "    layer.CreateField(ogr.FieldDefn(\"Y\", ogr.OFTReal))\n",
    "    # Process the text file and add the attributes and features to the shapefile\n",
    "    f = open('taipeibox_process/'+y+'.csv', 'r')  \n",
    "    for point in csv.reader(f):\n",
    "        if point[0]!=\"timestamp\":\n",
    "            # create the feature\n",
    "            feature = ogr.Feature(layer.GetLayerDefn())\n",
    "            # Set the attributes using the values from the delimited text file\n",
    "            feature.SetField(\"photoID\",point[7])\n",
    "            feature.SetField(\"userID\", point[8])\n",
    "            feature.SetField(\"time_D\", point[1])\n",
    "            feature.SetField(\"time_T\", point[2])\n",
    "            feature.SetField(\"Longitude\",point[3])\n",
    "            feature.SetField(\"Latitude\", point[4])\n",
    "            feature.SetField(\"Timestamp\",point[0])\n",
    "            feature.SetField(\"X\", point[5])\n",
    "            feature.SetField(\"Y\", point[6])\n",
    "\n",
    "            c_logitude=float(point[3])\n",
    "            c_latitude=float(point[4])\n",
    "            # create the WKT for the feature using Python string formatting\n",
    "            wkt = \"POINT(%f %f)\" %  (float(c_logitude) , float(c_latitude))\n",
    "\n",
    "            # Create the point from the Well Known Txt\n",
    "            point = ogr.CreateGeometryFromWkt(wkt)\n",
    "\n",
    "            # Set the feature geometry using the point\n",
    "            feature.SetGeometry(point)\n",
    "            # Create the feature in the layer (shapefile)\n",
    "            layer.CreateFeature(feature)\n",
    "            # Destroy the feature to free resources\n",
    "            feature.Destroy()\n",
    "    # Destroy the data source to free resources\n",
    "    data_source.Destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#get process feature count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened process_shp/2001.shp\n",
      "Number of features in 2001.shp: 96\n",
      "Opened process_shp/2002.shp\n",
      "Number of features in 2002.shp: 740\n",
      "Opened process_shp/2003.shp\n",
      "Number of features in 2003.shp: 1126\n",
      "Opened process_shp/2004.shp\n",
      "Number of features in 2004.shp: 1692\n",
      "Opened process_shp/2005.shp\n",
      "Number of features in 2005.shp: 13248\n",
      "Opened process_shp/2006.shp\n",
      "Number of features in 2006.shp: 19156\n",
      "Opened process_shp/2007.shp\n",
      "Number of features in 2007.shp: 50168\n",
      "Opened process_shp/2008.shp\n",
      "Number of features in 2008.shp: 90347\n",
      "Opened process_shp/2009.shp\n",
      "Number of features in 2009.shp: 131986\n",
      "Opened process_shp/2010.shp\n",
      "Number of features in 2010.shp: 162263\n",
      "Opened process_shp/2011.shp\n",
      "Number of features in 2011.shp: 200623\n",
      "Opened process_shp/2012.shp\n",
      "Number of features in 2012.shp: 201470\n",
      "Opened process_shp/2013.shp\n",
      "Number of features in 2013.shp: 299244\n",
      "Opened process_shp/2014.shp\n",
      "Number of features in 2014.shp: 256629\n",
      "Opened process_shp/2015.shp\n",
      "Number of features in 2015.shp: 164670\n",
      "1593458\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from osgeo import ogr\n",
    "cc=0\n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "# y_list=[2001,2002,2003,2004,2005]\n",
    "for yy in y_list:\n",
    "    y=str(yy)\n",
    "    SHP= \"process_shp/\"+y+\".shp\"\n",
    "    daShapefile = SHP\n",
    "\n",
    "    driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "\n",
    "    dataSource = driver.Open(daShapefile, 0) # 0 means read-only. 1 means writeable.\n",
    "\n",
    "    # Check to see if shapefile is found.\n",
    "    if dataSource is None:\n",
    "        print 'Could not open %s' % (daShapefile)\n",
    "    else:\n",
    "        print 'Opened %s' % (daShapefile)\n",
    "        layer = dataSource.GetLayer()\n",
    "        featureCount = layer.GetFeatureCount()\n",
    "        cc=cc+featureCount\n",
    "        print \"Number of features in %s: %d\" % (os.path.basename(daShapefile),featureCount)\n",
    "print cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#讀取taipei shp將資料clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 需要刪除clip資料夾中檔案\n",
    "import arcpy\n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "for yy in y_list:\n",
    "    y=str(yy)\n",
    "    c_shp= \"process_shp/\"+y+\".shp\"\n",
    "    arcpy.Clip_analysis(c_shp, \"tpe_shp/taipei_city.shp\", \"C:/thesis_flickr/clip/\"+y+\"clip.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#get taipei clip feature count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001 points 94 unique uid 8\n",
      "unique time_location 92\n",
      "unique_location 19\n",
      "2002 points 699 unique uid 40\n",
      "unique time_location 673\n",
      "unique_location 113\n",
      "2003 points 1051 unique uid 51\n",
      "unique time_location 1018\n",
      "unique_location 88\n",
      "2004 points 1547 unique uid 78\n",
      "unique time_location 1510\n",
      "unique_location 149\n",
      "2005 points 12866 unique uid 172\n",
      "unique time_location 12775\n",
      "unique_location 875\n",
      "2006 points 16777 unique uid 317\n",
      "unique time_location 16508\n",
      "unique_location 2295\n",
      "2007 points 44124 unique uid 563\n",
      "unique time_location 43448\n",
      "unique_location 7438\n",
      "2008 points 83471 unique uid 986\n",
      "unique time_location 80738\n",
      "unique_location 15322\n",
      "2009 points 116059 unique uid 1886\n",
      "unique time_location 114014\n",
      "unique_location 23326\n",
      "2010 points 144293 unique uid 2770\n",
      "unique time_location 141822\n",
      "unique_location 32205\n",
      "2011 points 176325 unique uid 3487\n",
      "unique time_location 172328\n",
      "unique_location 47292\n",
      "2012 points 169001 unique uid 3635\n",
      "unique time_location 160694\n",
      "unique_location 54001\n",
      "2013 points 239293 unique uid 5343\n",
      "unique time_location 229915\n",
      "unique_location 94633\n",
      "2014 points 209702 unique uid 4650\n",
      "unique time_location 202421\n",
      "unique_location 101319\n",
      "2015 points 137198 unique uid 3332\n",
      "unique time_location 130696\n",
      "unique_location 65808\n",
      "SUM of points 2705000\n",
      "UNIQUE all userID: 15735\n",
      "UNIQUE all time_location: 1310128\n",
      "UNIQUE all location: 425254\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from osgeo import ogr\n",
    "total=0\n",
    "all_uid=[]\n",
    "all_t_l=[]\n",
    "all_l=[]\n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "for yy in y_list:\n",
    "    year=str(yy)\n",
    "    uid_check=[]\n",
    "    t_l_check=[]\n",
    "    l_check=[]\n",
    "    SHP= \"clip/\"+year+\"clip.shp\"\n",
    "    daShapefile = SHP\n",
    "    driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "    dataSource = driver.Open(daShapefile, 0) # 0 means read-only. 1 means writeable. \n",
    "    layer = dataSource.GetLayer(0)\n",
    "    featureCount = layer.GetFeatureCount()\n",
    "    total=total+featureCount\n",
    "    for feature in layer:\n",
    "        userID = feature.GetField('userID')\n",
    "        timestamp = feature.GetField('timestamp')\n",
    "        x= feature.GetField('x')\n",
    "        y= feature.GetField('y')\n",
    "        total=total+1\n",
    "        uid_check.append(userID)\n",
    "        t_l_check.append(str(timestamp)+str(x)+str(y))\n",
    "        all_uid.append(userID)\n",
    "        all_t_l.append(userID+str(timestamp)+str(x)+str(y))\n",
    "        l_check.append(str(x)+str(y))\n",
    "        all_l.append(str(x)+str(y))\n",
    "    # Destroy the data source to free resources\n",
    "    dataSource.Destroy()\n",
    "    print year,\"points\",featureCount,\"unique uid\",len(set(uid_check))\n",
    "    print \"unique time_location\",len(set(t_l_check))\n",
    "    print \"unique_location\",len(set(l_check))\n",
    "print \"SUM of points\",total\n",
    "print \"UNIQUE all userID:\",len(set(all_uid))\n",
    "print \"UNIQUE all time_location:\",len(set(all_t_l))\n",
    "print \"UNIQUE all location:\",len(set(all_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "arcpy.env.workspace = \"C:/thesis_flickr/clip\"\n",
    "merge_list=[]\n",
    "y_list=[2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]\n",
    "for yy in y_list:\n",
    "    year=str(yy)\n",
    "    shp= year+\"clip.shp\"\n",
    "    merge_list.append(shp)\n",
    "print merge_list\n",
    "# #delete shp\n",
    "if os.path.exists(\"merge.shp\"):\n",
    "    driver.DeleteDataSource(\"merge.shp\")\n",
    "arcpy.Merge_management(merge_list, \"C:/thesis_flickr/merge.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#get merge feature count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1352500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from osgeo import ogr\n",
    "SHP= \"merge.shp\"\n",
    "daShapefile = SHP\n",
    "driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "dataSource = driver.Open(daShapefile, 0) # 0 means read-only. 1 means writeable. \n",
    "layer = dataSource.GetLayer(0)\n",
    "featureCount = layer.GetFeatureCount()\n",
    "print featureCount\n",
    "# Destroy the data source to free resources\n",
    "dataSource.Destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
